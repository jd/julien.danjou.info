---
title: "From decimal to timestamp with MySQL"
created: !!timestamp '2016-09-08 12:02:13'
image: /media/images/blog/2016/clock.jpg
tags:
    - Python
    - SQLAlchemy
    - Alembic
    - MySQL
    - PostgreSQL
    - OpenStack
    - Ceilometer
---

{% block excerpt %}
{% mark excerpt %}

When working with timestamps, one question that often arises is the precision
of those timestamps. Most software is good enough with a precision up to the
second, and that's easy. But in some cases, like working on metering, a finer
precision is required.

{% endmark %}
{% endblock %}

I don't know exactly why[Â¹](#why), and it makes me suffer every day, but
[OpenStack](http://openstack.org) is really tied to [MySQL](http://mysql.com)
(and its clones). It hurts because MySQL is a very poor solution if you want to
leverage your database to actually solve problems. But that's how life is,
unfair. And in the context of the projects I work on, that boils down to that
we can't afford to not support MySQL.

So here we are, needing to work with MySQL and at the same time requiring
timestamp with a finer precision than just seconds. And guess what: MySQL did
not support that until 2011.

## No microseconds in MySQL? No problem: DECIMAL!

MySQL 5.6.4 (released in 2011), a beta version of MySQL 5.6 (hello MySQL, ever
heard of [Semantic Versioning](http://semver.org)?), brought microsecond
precision to timestamps. But the first stable version supporting that, MySQL
5.6.10, was only released in 2013. So for a long time, there was a problem
without any solution.

The obvious workaround, in this case, is to reassess your choices in
technologies, discover that
[PostgreSQL supports microsecond precision for at least a decade](https://www.postgresql.org/docs/7.1/static/datatype-datetime.html)
and problem solved.

This is not what happened in our case, and in order to support MySQL, one had
to find a workaround. And so did they in our
[Ceilometer](http://launchpad.net/ceilometer) project, using a
[`DECIMAL`](https://dev.mysql.com/doc/refman/5.7/en/precision-math-decimal-characteristics.html)
type instead of `DATETIME`.

The `DECIMAL` type takes 2 arguments: the total number of digits you need to
store, and how many in that total will be used for the fractional part. Knowing
that the internal storage of MySQL uses 1 byte for 2 digits, 2 bytes for 4
digits, 3 bytes for 6 digits and 4 bytes for 9 digits, and that each part is
stored independently, in order to maximize your storage space, you want to pick
a number of digits that fits that correctly.

This is why Ceilometer picked 14 for the integer part (9 digits on 4 bytes and
5 digits on 3 bytes) and 6 for the decimal part (3 bytes).

<iframe src="//giphy.com/embed/QHHKoEeJ4AOOs" width="480" height="270"
frameBorder="0" class="giphy-embed illustration" allowFullScreen></iframe>

Wait. It's stupid because:

Ceilometer uses `DECIMAL(20, 6)` to store UNIX timestamp values from
1970 to 3170843 (that's the year for `(10^14)-1` seconds after epoch), 

- `DECIMAL(20, 6)` implies that you uses 14 digits for the integer part, which
  using epoch as a reference makes you able to encode timestamp `(10^14) - 1`
  which is year 3170843. I am certain Ceilometer won't last that far.
- 14 digits is 9 + 5 digits in MySQL which is 7 bytes, the same size that is
  used for 9 + 6 digits. So if you could have `DECIMAL(21, 6)` for the same
  storage space (and go up to year 31690708 which is a nice bonus, right?)

Well, I guess the original author of the patch did not read the documentation
entirely (`DECIMAL(20, 6)` being on the MySQL documentation page as an example,
I imagine it just has been copy-pasted blindly?).

The best choice for this use case would have been `DECIMAL(17, 6)` which would
allow storing 11 digits for integer (5 bytes), supporting timestamp up to
`(2^11)-1` (year 5138), and 6 digits for decimal part (3 bytes), using only 8
bytes in total per timestamp.

Nonetheless, this workaround has been implemented using a
[SQLAlchemy](http://sqlalchemy.org) custom type and works as expected:

{% syntax python %}
class PreciseTimestamp(sqlalchemy.types.TypeDecorator):
    """Represents a timestamp precise to the microsecond."""

    impl = sqlalchemy.DateTime

    def load_dialect_impl(self, dialect):
        if dialect.name == 'mysql':
            return sqlalchemy.dialect.type_descriptor(
                sqlalchemy.types.DECIMAL(precision=20,
                                         scale=6,
                                         asdecimal=True))
        return sqlalchemy.dialect.type_descriptor(self.impl)
{% endsyntax %}

## Microseconds in MySQL? Damn, migration!

As I said, MySQL 5.6.4 brought microseconds precision to the table (pun
intended). Therefore, it's a great time to migrate away from this hackish
format to the brand new one.

First, be aware that the default `DATETIME` type has no microseconds precision:
[you have to specify how many digits you want as an argument](http://dev.mysql.com/doc/refman/5.7/en/datetime.html).
To support microseconds, you should therefore use `DATETIME(6)`.

If we were using a great RDBMS, let's say, hum, PostgreSQL, we could do that
very easily, see:

{% syntax sql %}
postgres=# CREATE TABLE foo (mytime decimal);
CREATE TABLE
postgres=# \d foo
      Table "public.foo"
 Column â”‚  Type   â”‚ Modifiers
â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 mytime â”‚ numeric â”‚
postgres=# INSERT INTO foo (mytime) VALUES (1473254401.234);
INSERT 0 1
postgres=# ALTER TABLE foo ALTER COLUMN mytime SET DATA TYPE timestamp with time zone USING to_timestamp(mytime);
ALTER TABLE
postgres=# \d foo
              Table "public.foo"
 Column â”‚           Type           â”‚ Modifiers
â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 mytime â”‚ timestamp with time zone â”‚

postgres=# select * from foo;
           mytime
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 2016-09-07 13:20:01.234+00
(1 row)
{% endsyntax %}

And since this is a pretty common use case, it's even
[an example in the PostgreSQL documentation](https://www.postgresql.org/docs/9.5/static/sql-altertable.html).
The version from the documentation uses a calculation based on epoch, whereas
my example here leverages the `to_timestamp()` function. That's my personal
touch.

Obviously, doing this conversion in a single line is not possible with MySQL:
it does not implement the `USING` keyword on `ALTER TABLE â€¦ ALTER COLUMN`. So
what's the solution gonna be? Well, it's a 4 steps job:

1. Create a new column of type `DATETIME(6)`
2. Copy data from the old column to the new column, converting them to the new
   format
3. Delete the old column
4. Rename the new column to the old column name.

But I know what you're thinking: there are 4 steps, but that's not a problem,
we'll just use a transaction and embed these operations inside.

<iframe src="//giphy.com/embed/lgn6HaiiwHBXW" width="480" height="269"
frameBorder="0" class="giphy-embed illustration" allowFullScreen></iframe>

[MySQL does not support transactions on data definition language (DDL)](http://dev.mysql.com/doc/refman/5.7/en/cannot-roll-back.html).
So if any of those steps fails, you'll be unable rollback steps 1, 3 and 4. Who
knew that using MySQL was like living on the edge, right?

<iframe src="//giphy.com/embed/XIFNo90bD5RYY" width="480" height="270"
frameBorder="0" class="giphy-embed illustration" allowFullScreen></iframe>

## Doing this in Python with our friend Alembic

I like [Alembic](http://alembic.zzzcomputing.com/). It's a Python library based
on [SQLAlchemy](http://sqlalchemy.org) that handles schema migration for your
favorite RDBMS.

Once you created a new alembic migration script using `alembic revision`, it's
time to edit it and write something along those lines:

{% syntax python %}
from alembic import op
import sqlalchemy as sa
from sqlalchemy.sql import func

class Timestamp(sa.types.TypeDecorator):
    """Represents a timestamp precise to the microsecond."""

    impl = sqlalchemy.DateTime

    def load_dialect_impl(self, dialect):
        if dialect.name == 'mysql':
            return dialect.type_descriptor(mysql.DATETIME(fsp=6))
        return self.impl

def upgrade():
    bind = op.get_bind()
    if bind and bind.engine.name == "mysql":
        existing_type = sa.types.DECIMAL(
            precision=20, scale=6, asdecimal=True)
        existing_col = sa.Column("mytime", existing_type, nullable=False)
        temp_col = sa.Column("mytime_ts", Timestamp(), nullable=False)
        # Step 1: ALTER TABLE mytable ADD COLUMN mytime_ts DATETIME(6)
        op.add_column("mytable", temp_col)
        t = sa.sql.table("mytable", existing_col, temp_col)
        # Step 2: UPDATE mytable SET mytime_ts=from_unixtime(mytime)
        op.execute(t.update().values(mytime_ts=func.from_unixtime(existing_col)}))
        # Step 3: ALTER TABLE mytable DROP COLUMN mytime
        op.drop_column("mytable", "mytime")
        # Step 4: ALTER TABLE mytable CHANGE mytime_ts mytime
        # Note: MySQL needs to have all the old/new information to just rename a columnâ€¦
        op.alter_column("mytable",
                        "mytime_ts",
                        nullable=False,
                        type_=Timestamp(),
                        existing_nullable=False,
                        existing_type=existing_type,
                        new_column_name="mytime")
{% endsyntax %}

In MySQL, the function to convert a float to a UNIX timestamp is
`from_unixtime()`, so the script leverages it to convert the data. As said,
you'll notice we don't bother using any kind of transaction, so if anything
goes wrong, there's no rollback, and it won't be possible to re-run the
migration without a manual intervention.

`TimestampUTC` is a custom class that implements `sqlalchemy.DateTime` using a
`DATETIME(6)` type for MySQL, and a regular `sqlalchemy.DateTime` type for
other back-ends. It is used by the rest of the code (e.g. ORM model) but I've
pasted it in this example for a better understanding.

Once written, you can easily test your migration using
[_pifpaf_](https://github.com/jd/pifpaf) to run a temporary database:

{% syntax shell %}
$ pifpaf run mysql $SHELL
$ alembic -c alembic/alembic.ini upgrade 1c98ac614015 # upgrade to the initial revision
$ mysql -S $PIFPAF_MYSQL_SOCKET pifpaf
mysql> INSERT INTO mytable (mytime) VALUES (1325419200.213000);
Query OK, 1 row affected (0.00 sec)

mysql> SELECT * FROM mytable;
+-------------------+
| mytime            |
+-------------------+
| 1325419200.213000 |
+-------------------+
1 row in set (0.00 sec)

$ alembic -c alembic/alembic.ini upgrade head

$ mysql -S $PIFPAF_MYSQL_SOCKET pifpaf
mysql> SELECT * FROM mytable;
+----------------------------+
| mytime                     |
+----------------------------+
| 2012-01-01 13:00:00.213000 |
+----------------------------+
1 row in set (0.00 sec)
{% endsyntax %}

And voilÃ , we just migrated unsafely our data to a new fancy format. Thank you
Alembic for solving a problem we would not have without MySQL. ðŸ˜Š

<iframe src="//giphy.com/embed/cMq7gwTNX4jTO" width="480" height="382"
frameBorder="0" class="giphy-embed illustration" allowFullScreen></iframe>


{# Local Variables: #}
{# mode: markdown #}
{# End: #}
